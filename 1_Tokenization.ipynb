{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNs/c3PseFUNLG4oXYcC0dS"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenization** is basically giving **numerical tokens** to different words in Natural Language Processing"
      ],
      "metadata": {
        "id": "J2S0V_5WzMRH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBEqc-4Hg2cd",
        "outputId": "1f1735c3-0420-4c64-ad8e-ed7a36989538"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'my': 1, 'name': 2, 'is': 3, 'patel': 4, 'dhruval': 5, \"brother's\": 6, 'shivam': 7, \"mother's\": 8, 'varsha': 9, 'i': 10, 'am': 11, 'a': 12, 'computer': 13, 'science': 14, 'engineer': 15, \"father's\": 16, 'mr': 17, 'ketan': 18}\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "#this is my sentence data\n",
        "sentences=[\"My name is Dhruval Patel\",\n",
        "           \"My brother's name is Shivam Patel\",\n",
        "           \"My mother's name is Varsha Patel\",\n",
        "           \"I am a computer science engineer\",\n",
        "           \"My father's name is Mr. Ketan Patel.\"]\n",
        "\n",
        "# creating a tokenizer object that will take the text as input and generate respective tokens for each word in a sentence\n",
        "tokenizer=Tokenizer(num_words=100)\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index=tokenizer.word_index\n",
        "\n",
        "#printing the representation\n",
        "print(word_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting **texts** to **sequences**\n",
        "\n"
      ],
      "metadata": {
        "id": "5J2OD1r00D9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequences=tokenizer.texts_to_sequences(sentences)\n",
        "print(\"This is the word index: ------ \\n\")\n",
        "print(word_index)\n",
        "print(\"This is the word sequence: ------ \\n\")\n",
        "print(sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivXr4Tiez-vx",
        "outputId": "0c69f911-e292-441d-fa40-ef64e999dc6c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the word index: ------ \n",
            "\n",
            "{'my': 1, 'name': 2, 'is': 3, 'patel': 4, 'dhruval': 5, \"brother's\": 6, 'shivam': 7, \"mother's\": 8, 'varsha': 9, 'i': 10, 'am': 11, 'a': 12, 'computer': 13, 'science': 14, 'engineer': 15, \"father's\": 16, 'mr': 17, 'ketan': 18}\n",
            "This is the word sequence: ------ \n",
            "\n",
            "[[1, 2, 3, 5, 4], [1, 6, 2, 3, 7, 4], [1, 8, 2, 3, 9, 4], [10, 11, 12, 13, 14, 15], [1, 16, 2, 3, 17, 18, 4]]\n"
          ]
        }
      ]
    }
  ]
}