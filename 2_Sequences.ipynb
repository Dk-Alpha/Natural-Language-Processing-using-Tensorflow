{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3tlzKkDU/7ieLhpX24yun",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dk-Alpha/Natural-Language-Processing-using-Tensorflow/blob/main/2_Sequences.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEzqfER31kUC",
        "outputId": "0f1bf003-4d2c-4984-9887-981d78759315"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'hi': 1, 'there': 2, 'it': 3, 'is': 4, 'me': 5, 'your': 6, 'friend': 7, 'i': 8, 'am': 9, 'so': 10, 'happy': 11, 'to': 12, 'meet': 13, 'an': 14, 'opponent': 15, 'like': 16, 'you': 17}\n"
          ]
        }
      ],
      "source": [
        "#Importing libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "#THIS IS THE SENTENCES USED FOR CREATING TOKENS/TRAINING\n",
        "training_sentences=[\"Hi there it is me your friend!\",\n",
        "                    \"I am so happy to meet an opponent like you\"]\n",
        "\n",
        "#CREATING TOKEN OBJECT AND FITTING WORDS\n",
        "tk=Tokenizer(num_words=100)\n",
        "tk.fit_on_texts(training_sentences)\n",
        "word_index=tk.word_index\n",
        "\n",
        "print(word_index)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testing_sentences=[\"Hi there it is me your Dhruval!\",   #contains 7 words\n",
        "                    \"I am so happy to meet a worthy opponent like you\"] #contains 11 words          #Here 'Dhruval', 'worhty','a' are new words that have not been included in the tokenzier                 "
      ],
      "metadata": {
        "id": "15ULWhgE2n_n"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Method 1: Simple Sequencing"
      ],
      "metadata": {
        "id": "v7OD3kQT3DjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq=tk.texts_to_sequences(testing_sentences)\n",
        "print(seq)\n",
        "#the output contains 6 words and 10 words respectively\n",
        "#words that are not tokenized are skipped"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qk5wx8A43C69",
        "outputId": "44380d19-45bd-4757-b7d1-4ce1efe3752e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 2, 3, 4, 5, 6], [8, 9, 10, 11, 12, 13, 15, 16, 17]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Method 2: Sequencing using **OOV**"
      ],
      "metadata": {
        "id": "CeofM6aF34j2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tk=Tokenizer(num_words=100,oov_token=\"<OOV>\")     #oov token replaces any un-countered word with the specified text\n",
        "tk.fit_on_texts(training_sentences)\n",
        "word_index=tk.word_index\n",
        "\n",
        "print(\"Word Index\\n\",word_index)\n",
        "\n",
        "seq=tk.texts_to_sequences(testing_sentences)\n",
        "\n",
        "print(\"Sequences:\\n\",seq)\n",
        "#It helps maintain the sequence length as the same length as the original sentence. Even if it encounters unknown data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Il8sDU8H33-H",
        "outputId": "ab1047b7-3af8-4309-8ecc-71bdaa842e15"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Index\n",
            " {'<OOV>': 1, 'hi': 2, 'there': 3, 'it': 4, 'is': 5, 'me': 6, 'your': 7, 'friend': 8, 'i': 9, 'am': 10, 'so': 11, 'happy': 12, 'to': 13, 'meet': 14, 'an': 15, 'opponent': 16, 'like': 17, 'you': 18}\n",
            "Sequences:\n",
            " [[2, 3, 4, 5, 6, 7, 1], [9, 10, 11, 12, 13, 14, 1, 1, 16, 17, 18]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handling Sentences of different length using padding\n",
        "> pre padding or post padding\n",
        "\n"
      ],
      "metadata": {
        "id": "HbSEYqMo57a5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "padded_seq=pad_sequences(seq,padding=\"post\")        #using padding parameter for pre or post padding\n",
        "\n",
        "print(padded_seq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkWoBYFq56kF",
        "outputId": "87f12ea0-5034-4e27-e3a0-0263e978b935"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2  3  4  5  6  7  1  0  0  0  0]\n",
            " [ 9 10 11 12 13 14  1  1 16 17 18]]\n"
          ]
        }
      ]
    }
  ]
}